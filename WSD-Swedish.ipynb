{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/.vn/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating data\n",
      "1520 / 10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ninspector.filter().scope().context().most_attended_to(k=3)\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import pandas\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
    "\n",
    "from lm_inspect import LanguageModelInspector\n",
    "\n",
    "class BERTEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, model_name, device, sample_size):\n",
    "        super().__init__()\n",
    "        config = AutoConfig.from_pretrained(model_name,\n",
    "                                            output_hidden_states=True,\n",
    "                                            output_attentions=True\n",
    "                                            )\n",
    "        self.bert = AutoModel.from_pretrained(model_name, config=config)\n",
    "        self.output_size = self.bert.config.hidden_size\n",
    "        self.device = device\n",
    "\n",
    "        # For logging purposes\n",
    "        self.sample_idx = 0\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "    def forward(self, documents):\n",
    "        # Convert the encoded sequences to a tensor.\n",
    "        docs = torch.tensor([d['doc'] for d in documents]).to(self.device)\n",
    "        # Get the word representations of all sequences.\n",
    "        bert_outputs = self.bert(docs)\n",
    "        # Use the top layer of BERT\n",
    "        top_layer_output = bert_outputs[0]\n",
    "        # word_outputs will store the word representation of the ambigious word.\n",
    "        word_outputs = torch.empty( len(documents), self.bert.config.hidden_size).to(self.device)\n",
    "        #word_outputs = top_layer_output[:,0,:]\n",
    "        for idx, d in enumerate(documents):\n",
    "          pos = d['pos']\n",
    "          word_outputs[idx] = top_layer_output[idx, pos]\n",
    "\n",
    "        # For logging purposes, since this can take a long time.\n",
    "        print('\\r' + str(self.sample_idx) + \" / \" + str(self.sample_size), end='')\n",
    "        sys.stdout.flush()\n",
    "        self.sample_idx += len(documents)\n",
    "        if self.sample_idx >= self.sample_size:\n",
    "          self.sample_idx = 0\n",
    "\n",
    "        return word_outputs\n",
    "\n",
    "encoder = BERTEncoder('KB/bert-base-swedish-cased', 'cuda', 10000)\n",
    "\n",
    "def context(doc, pos, window_size):\n",
    "\n",
    "  new_pos = pos\n",
    "  if pos < window_size:\n",
    "    left = 0\n",
    "  else:\n",
    "    left = pos - window_size\n",
    "    new_pos = window_size\n",
    "\n",
    "  window_doc = doc[left: pos + window_size]\n",
    "\n",
    "  # Sanity check that new_pos still refers to the ambigious word.\n",
    "  assert doc[pos] == window_doc[new_pos]\n",
    "\n",
    "  return {'doc': window_doc, 'pos': new_pos}\n",
    "\n",
    "def read_data(filename, window_size):\n",
    "  column_names = ['sense_key', 'lemma', 'pos', 'text']\n",
    "  df = pandas.read_csv(filename, sep='\\t', names=column_names)\n",
    "  X = []\n",
    "  Y = []\n",
    "  for idx, row in df.iterrows():\n",
    "    pos, text, sense_key = row['pos'], row['text'].split(), row['sense_key']\n",
    "    c = context(text, pos, window_size)\n",
    "    X.append(c)\n",
    "    Y.append(sense_key)\n",
    "  return X, Y\n",
    "\n",
    "def bert_tokenize_and_encode(tokenizer, X, max_len):\n",
    "  for x in X:\n",
    "    x['doc'] = tokenizer.encode(x['doc'], max_length=max_len, pad_to_max_length=True, add_special_tokens=False, truncation=True)\n",
    "  return X\n",
    "\n",
    "Xval, Yval = read_data('../swedish_wsd/swedish_lexical_sample_GOLD_corpus.csv', 32)\n",
    "\n",
    "seq = torch.nn.Sequential(\n",
    "            encoder,\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(encoder.output_size, out_features=358)\n",
    "        ).to('cuda')\n",
    "state_dict = torch.load('models/KB-bert-swedish-cased-wsd.pt')\n",
    "seq.load_state_dict(state_dict)\n",
    "\n",
    "#_, Xval, _, Yval = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "#Xval, Yval = zip(*[ (x, y) for x, y in zip(Xval,Yval) if y == 'case%1:26:00::'])\n",
    "\n",
    "config = AutoConfig.from_pretrained('KB/bert-base-swedish-cased',\n",
    "                                    output_hidden_states=True,\n",
    "                                    output_attentions=True\n",
    "                                    )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased', config=config)\n",
    "Xval = bert_tokenize_and_encode(tokenizer, Xval, 64)\n",
    "inspector = LanguageModelInspector(seq, Xval, Yval, tokenizer)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "inspector.filter().scope().context().most_attended_to(k=3)\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.config({ \n",
       "     paths: { \n",
       "     d3: 'https://d3js.org/d3.v4.min'\n",
       "}});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "require.config({ \n",
    "     paths: { \n",
    "     d3: 'https://d3js.org/d3.v4.min'\n",
    "}});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = [x['pos'] for x in Xval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <body>\n",
       "          <div id=\"container\">\n",
       "            <table id=\"model\">\n",
       "            </table>\n",
       "            <table id=\"topk\">\n",
       "            </table>\n",
       "          <div/>\n",
       "        </body>\n",
       "        <style>#container {\n",
       "  float:left;\n",
       "  display: flex;\n",
       "  margin: 10px;\n",
       "}\n",
       "\n",
       "#model {\n",
       "  font-size: 16px;\n",
       "  font: 16px monospace\n",
       "}\n",
       "\n",
       "td {\n",
       "  padding: 5px;\n",
       "  border-bottom: 1px solid black;\n",
       "}\n",
       "\n",
       "td.update {\n",
       "  color: blue;\n",
       "}\n",
       "\n",
       "td.enter {\n",
       "  color: green;\n",
       "}\n",
       "\n",
       "td.exit, tr.exit td {\n",
       "  color: red;\n",
       "}\n",
       "\n",
       "td.row-header {\n",
       "  border-right: 1px solid black;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "        <script>\n",
       "            results = {'indices': [[[43, 1, 65, 31, 4352, 10534, 369, 33708, 955, 3418]], [[1, 43, 3418, 31, 65, 36, 48, 19, 59, 97]], [[1, 43, 3418, 48, 19, 36, 59, 31, 67, 97]], [[43, 1, 3418, 65, 31, 36, 48, 54, 67, 59]]], 'values': [[[3.15171480178833, 2.1640560626983643, 1.6320754289627075, 0.9600701928138733, 0.9268279075622559, 0.9107046723365784, 0.7093968987464905, 0.6589178442955017, 0.6245617270469666, 0.6012330055236816]], [[3.60221004486084, 2.019324779510498, 0.9087089896202087, 0.8712644577026367, 0.8023785352706909, 0.760337233543396, 0.7065112590789795, 0.7045735716819763, 0.6765252351760864, 0.6378535032272339]], [[4.458037376403809, 2.2702834606170654, 2.062605381011963, 1.7654361724853516, 1.2428795099258423, 0.934039831161499, 0.8571422696113586, 0.8307661414146423, 0.8072570562362671, 0.6913917660713196]], [[5.294958114624023, 4.871442794799805, 4.472289085388184, 2.6075735092163086, 1.40370774269104, 1.362730860710144, 1.1075305938720703, 1.0655372142791748, 0.9397718906402588, 0.931483268737793]]]}\n",
       "            tokenizer = {43: 'för', 1: '[UNK]', 65: 'av', 31: 'i', 4352: 'avgörande', 10534: 'kristna', 369: 'stor', 33708: 'strategisk', 955: 'större', 3418: 'betydelse', 36: 'och', 48: 'att', 19: ',', 59: 'en', 97: 'den', 67: 'som', 54: 'är'}\n",
       "            require.config({paths: {d3: \"https://d3js.org/d3.v4.min\"}}); // FIX TO MAKE DYNAMIC\n",
       "require([\"d3\"], function(d3) {\n",
       "  var margin = {top: 1, right: 1, bottom: 1, left: 1},\n",
       "      width = 300 - margin.left - margin.right,\n",
       "      height = 145 - margin.top - margin.bottom;\n",
       "\n",
       "    function round(value, decimals) {\n",
       "      return Number(Math.round(value+'e'+decimals)+'e-'+decimals);\n",
       "    }\n",
       "\n",
       "    window.fetchByLabels = function(labels, layers, heads, type) {\n",
       "      return new Promise((resolve, reject) => {\n",
       "          var callbacks = {\n",
       "              iopub: {\n",
       "                  output: (data) => resolve(data.content.text.trim())\n",
       "              }\n",
       "          };\n",
       "          Jupyter.notebook.kernel.execute(`print(${python})`, callbacks);\n",
       "      });\n",
       "    };\n",
       "\n",
       "    // Temporary hack\n",
       "    var data = results;\n",
       "    var tmpTokenizer = tokenizer;\n",
       "\n",
       "    var uniqueIndices = data.indices\n",
       "      .reduce((prev, curr) => prev.concat(curr), [])\n",
       "      .reduce((prev, curr) => prev.concat(curr), [])\n",
       "      .filter((item, i, arr) => arr.indexOf(item) === i);\n",
       "\n",
       "\n",
       "\n",
       "    var myColor = d3.scaleOrdinal().domain(uniqueIndices).range(d3.schemeCategory20b);//([\"gold\", \"blue\", \"green\", \"yellow\", \"black\", \"grey\", \"darkgreen\", \"pink\", \"brown\", \"slateblue\", \"grey1\", \"orange\"])\n",
       "\n",
       "    window.decodeWord = function(index) {\n",
       "      return tmpTokenizer[index];\n",
       "    };\n",
       "\n",
       "    var modelTable = d3.select('#model');\n",
       "    var topkList = d3.select('#topk');\n",
       "\n",
       "    var update = function(nofLayers, nofHeads, nofWords = 10) {\n",
       "\n",
       "      var svg = modelTable\n",
       "        .selectAll(\"tr\")\n",
       "        .data([...Array(nofHeads).keys()])\n",
       "        .enter()\n",
       "        .append(\"tr\")\n",
       "        .attr(\"head\", function(d) {\n",
       "          return d;\n",
       "        })\n",
       "        .selectAll(\"th\")\n",
       "        .data([...Array(nofLayers).keys()])\n",
       "        .enter()\n",
       "        .append(\"th\")\n",
       "        .attr(\"layer\", function(d) {\n",
       "          return d;\n",
       "        })\n",
       "        .append(\"svg\");\n",
       "\n",
       "      var svgData =\n",
       "        svg\n",
       "        .selectAll(\"rect\")\n",
       "        .data(function(d) {\n",
       "          var head = parseInt(this.parentNode.parentNode.getAttribute(\"head\"));\n",
       "          var layer = d;\n",
       "          var top = data.indices[layer][head].map(function(d, i) {\n",
       "            return {\"id\": d, \"value\": data.values[layer][head][i]};\n",
       "          });\n",
       "          top.push({\"id\": \"root\"});\n",
       "          var topWords = data.indices[layer][head];\n",
       "          var topValues = data.values[layer][head];\n",
       "          topWords.push(\"root\");\n",
       "          topValues.push(\"root\");\n",
       "          var root = d3.stratify()\n",
       "            .id(function(d) { return d.id; })   // Name of the entity (column name is name in csv)\n",
       "            .parentId(function(d, i) {\n",
       "              return d.id === \"root\" ? \"\" : \"root\";\n",
       "            })   // Name of the parent (column name is parent in csv)\n",
       "          (top);\n",
       "          root.sum(function(d,i) {\n",
       "            return +d.value;\n",
       "          });\n",
       "          d3.treemap()\n",
       "            .size([width, height])\n",
       "            .padding(4)\n",
       "            (root);\n",
       "          return root.leaves();\n",
       "        })\n",
       "        .enter();\n",
       "        svgData.append(\"rect\")\n",
       "          .attr('x', function (d) { return d.x0; })\n",
       "          .attr('y', function (d) { return d.y0; })\n",
       "          .attr('width', function (d) { return d.x1 - d.x0; })\n",
       "          .attr('height', function (d) { return d.y1 - d.y0; })\n",
       "          .style(\"stroke\", \"black\")\n",
       "          //.style(\"fill\", \"#69b3a2\")\n",
       "          .style(\"fill\", function(d) {return myColor(d.id); })\n",
       "        //.select(function() {return this.parentNode;})\n",
       "        svgData.append(\"text\")\n",
       "          .attr('x', function (d) { return d.x0+10; })\n",
       "          .attr('y', function (d) { return d.y0+20; })\n",
       "          .text(function(d) {return window.decodeWord(d.id);})\n",
       "          .attr(\"font-size\", \"15px\")\n",
       "          .attr(\"fill\", \"white\");\n",
       "        svgData.append(\"text\")\n",
       "          .attr('x', function (d) { return d.x0+10; })\n",
       "          .attr('y', function (d) { return d.y0+40; })\n",
       "          .text(function(d) {\n",
       "            var prob = d.value;\n",
       "            var percentage = round(prob, 3);\n",
       "            console.log(percentage);\n",
       "            return `${percentage}`;\n",
       "          })\n",
       "          .attr(\"font-size\", \"15px\")\n",
       "          .attr(\"fill\", \"white\");\n",
       "\n",
       "\n",
       "      // Head labels\n",
       "      modelTable\n",
       "        .insert(\"tr\", \"tr\")\n",
       "        .selectAll(\"th\")\n",
       "        .data([...Array(nofLayers)])\n",
       "        .enter()\n",
       "        .append(\"th\")\n",
       "        .html(function(_, d) {\n",
       "          return `l<sub>${d}</sub>`;\n",
       "        });\n",
       "\n",
       "     //Layer labels\n",
       "     modelTable\n",
       "      .selectAll(\"tr\")\n",
       "      .insert(\"th\", \"th\")\n",
       "      .html(function() {\n",
       "        var head = this.parentNode.getAttribute(\"head\");\n",
       "        if (head) {\n",
       "          return `h<sub>${head}</sub>`;\n",
       "        }\n",
       "      });\n",
       "\n",
       "      topkList\n",
       "        .selectAll('tr')\n",
       "        .data(data['indices'][nofLayers-1][nofHeads-1])\n",
       "        .enter()\n",
       "        .append('tr')\n",
       "        .append('th')\n",
       "        .text(function(d) {\n",
       "          return window.decodeWord(d);\n",
       "        })\n",
       "        .style(\"background-color\", function(d) {\n",
       "          return myColor(d);\n",
       "        })\n",
       "        .style(\"color\", function(d) {\n",
       "          return \"white\";\n",
       "        })\n",
       "        .select(function() {\n",
       "          return this.parentNode;\n",
       "        })\n",
       "        .append('th')\n",
       "        .text(function(d, i) {\n",
       "          var prob =  data['values'][nofLayers-1][nofHeads-1][i]\n",
       "          var percentage = round(prob, 3) * 100\n",
       "          return `${percentage}`;\n",
       "        });\n",
       "    };\n",
       "    /*\n",
       "\n",
       "    JSON response type (v1):\n",
       "\n",
       "    {\n",
       "      topk: [\n",
       "        {\n",
       "          \"word\": <word\"\n",
       "          \"prob\": 0-1\n",
       "        },\n",
       "        ...\n",
       "      ]\n",
       "\n",
       "\n",
       "    }\n",
       "\n",
       "    JSON response type (v2):\n",
       "\n",
       "    {\n",
       "      layers: [\n",
       "        0: {\n",
       "            \"word\": <word>,\n",
       "            \"prob\": 0 ... 1\n",
       "          },\n",
       "          { ... }\n",
       "        1: { ... }\n",
       "        ...\n",
       "        12:\n",
       "          {\n",
       "            \"word\": <word>,\n",
       "            \"prob:\" 0 ... 1\n",
       "          }\n",
       "      ],\n",
       "\n",
       "      agg: [\n",
       "        sum: [\n",
       "          {...}\n",
       "        ],\n",
       "        last_layer: [\n",
       "          {...}\n",
       "        ]\n",
       "      ],\n",
       "\n",
       "\n",
       "    }\n",
       "    */\n",
       "\n",
       "    var nofLayers = data.indices.length;\n",
       "    var nofHeads = data.indices[0].length;\n",
       "\n",
       "    update(nofLayers, nofHeads);\n",
       "\n",
       "    // Generate and display some random table data\n",
       "\n",
       "});\n",
       "\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = inspector.topk_most_attended(k=10, label='betydelse_1_2', layer=[0,3, 6, 11], head=1, input_id = input_ids, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([44, 4, 1, 1, 50325])\n"
     ]
    }
   ],
   "source": [
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
